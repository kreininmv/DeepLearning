{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFTMJ2v-5YpN"
   },
   "source": [
    "# Homework 2. Training networks in PyTorch\n",
    "\n",
    "Это домашнее задание посвящено отработки навыков по написанию и обучению нейронных сетей. Ваше задание реализовать обучение нейронной сети и выполнить задания по анализу сети в конце ноутбука. Удачи!\n",
    "\n",
    "<font color='red'> **Дедлайн 4 октября 23:59 (жесткий)**  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3dj1mfT5Yp4"
   },
   "source": [
    "### Data loading in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UKLLAvNt5Yp5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h626FYAm5Yp6"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2oqonVb5Yp7"
   },
   "source": [
    "You will works with a MNIST dataset. It contains grayscale images of handwritten digits of size 28 x 28. The number of training objects is 60000.\n",
    "\n",
    "\n",
    "In pytorch, there is a special module to download MNIST. But for us it is more convinient to load the data ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3vZ3StbV5Yp7"
   },
   "outputs": [],
   "source": [
    "from util import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bOxvlgne5Yp9"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q6eiPbL5Yp-"
   },
   "source": [
    "The code below prepares short data (train and val) for seminar purposes (use this data to quickly learn model on CPU and to tune the hyperparameters). Also, we prepare the full data (train_full and test) to train a final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IJS2adK5Yp_",
    "outputId": "2934b5dd-ebd1-4c6c-c8a3-843640809288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle data\n",
    "X_train, y_train, X_test, y_test = load_mnist()\n",
    "np.random.seed(0)\n",
    "idxs = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, y_train = X_train[idxs], y_train[idxs]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYzxQ2Mf5Yp_"
   },
   "source": [
    "Pytorch offers convinient class DataLoader for mini batch generation. You should pass instance of Tensor Dataset to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOmqt8aE5Yp_",
    "outputId": "7202ab2e-184a-4a15-b9d8-b1a1d2985149"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1841923/2756627480.py:3: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.from_numpy(y).long())\n"
     ]
    }
   ],
   "source": [
    "def get_loader(X, y, batch_size=64):\n",
    "    train = torch.utils.data.TensorDataset(torch.from_numpy(X).float(),\n",
    "                                       torch.from_numpy(y).long())\n",
    "    train_loader = torch.utils.data.DataLoader(train,\n",
    "                                               batch_size=batch_size)\n",
    "    return train_loader\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_mnist()\n",
    "np.random.seed(0)\n",
    "idxs = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, y_train = X_train[idxs], y_train[idxs]\n",
    "# for final model:\n",
    "train_loader_full = get_loader(X_train, y_train)\n",
    "test_loader = get_loader(X_test, y_test)\n",
    "# for validation purposes:\n",
    "train_loader = get_loader(X_train[:15000], y_train[:15000])\n",
    "val_loader = get_loader(X_train[15000:30000], y_train[15000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOfwqdwJ5YqA",
    "outputId": "020f479a-f964-4a23-833d-8ffacb784c27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15000, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of objects\n",
    "val_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRoL5vqr5YqB"
   },
   "source": [
    "### Building LeNet-5\n",
    "\n",
    "Convolutional layer (from Anton Osokin's presentation):\n",
    "\n",
    "![slide](https://github.com/nadiinchi/dl_labs/raw/master/convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WokmLD85YqB"
   },
   "source": [
    "You need to implement Lenet-5:\n",
    "\n",
    "![Архитектура LeNet-5](https://www.researchgate.net/profile/Vladimir_Golovko3/publication/313808170/figure/fig3/AS:552880910618630@1508828489678/Architecture-of-LeNet-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc-cF7o35YqD"
   },
   "source": [
    "Construct a network according to the image and code examples given above. Use ReLU nonlinearity (after all linear and convolutional layers). The network must support multiplying the number of convolutions in each convolutional layer by k.\n",
    "\n",
    "Please note that on the scheme the size of the image is 32 x 32 but in our code the size is 28 x 28.\n",
    "\n",
    "Do not apply softmax at the end of the forward pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWfeNQ9gPhXo"
   },
   "source": [
    "### <font color='red'>[TODO] Написание архитектуры Le-Net-5 </font>\n",
    "\n",
    "В этой части вам нужно реализовать архитектуру Le-Net-5, но учтите, что на вход изображения приходит 28x28.\n",
    "\n",
    "Для того, написать архитектуру используйте [nn.Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), [nn.AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html), [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html). Ориентируйтесь на картинку сверху в реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7ipU_aYypKmm"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "k9AXOaVh5YqE"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        #super(CNN, self).__init__(num_channels = 1)\n",
    "        super(CNN, self).__init__()\n",
    "        ### your code here: define layers\n",
    "        #self.padding = torchvision.transforms.Pad(padding=2, fill=0,padding_mode='constant')\n",
    "        self.conv1   = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.pool1   = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2   = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, bias=True)\n",
    "        self.pool2   = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.flat    = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(in_features=400, out_features=120, bias=True)\n",
    "        self.linear2 = nn.Linear(in_features=120, out_features=84, bias=True)\n",
    "        self.linear3 = nn.Linear(in_features=84, out_features=10, bias=True)\n",
    "        self.relu    = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### your code here: transform x using layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CNN_v2(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        #super(CNN, self).__init__(num_channels = 1)\n",
    "        super(CNN_v2, self).__init__()\n",
    "        ### your code here: define layers\n",
    "        #self.padding = torchvision.transforms.Pad(padding=2, fill=0,padding_mode='constant')\n",
    "        self.conv1   = nn.Conv2d(in_channels=1, out_channels=24, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.pool1   = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2   = nn.Conv2d(in_channels=24, out_channels=64, kernel_size=5, stride=1, bias=True)\n",
    "        self.pool2   = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.flat    = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(in_features=1600, out_features=120, bias=True)\n",
    "        self.linear2 = nn.Linear(in_features=120, out_features=84, bias=True)\n",
    "        self.linear3 = nn.Linear(in_features=84, out_features=10, bias=True)\n",
    "        self.relu    = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### your code here: transform x using layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CNN_v3(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        #super(CNN, self).__init__(num_channels = 1)\n",
    "        super(CNN_v3, self).__init__()\n",
    "        ### your code here: define layers\n",
    "        #self.padding = torchvision.transforms.Pad(padding=2, fill=0,padding_mode='constant')\n",
    "        self.conv1   = nn.Conv2d(in_channels=1, out_channels=24, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.pool1   = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2   = nn.Conv2d(in_channels=24, out_channels=64, kernel_size=5, stride=1, bias=True)\n",
    "        self.pool2   = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.flat    = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(in_features=1600, out_features=120, bias=True)\n",
    "        self.linear2 = nn.Linear(in_features=120, out_features=10, bias=True)\n",
    "        self.relu    = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### your code here: transform x using layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4BYDgVO5YqE"
   },
   "source": [
    "Let's count the number of the parameters in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "cnn = CNN()\n",
    "summary(cnn, input_size=(32768, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DMqTaKi_5YqF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_v2                                   [32768, 10]               --\n",
       "├─Conv2d: 1-1                            [32768, 24, 28, 28]       624\n",
       "├─ReLU: 1-2                              [32768, 24, 28, 28]       --\n",
       "├─AvgPool2d: 1-3                         [32768, 24, 14, 14]       --\n",
       "├─Conv2d: 1-4                            [32768, 64, 10, 10]       38,464\n",
       "├─ReLU: 1-5                              [32768, 64, 10, 10]       --\n",
       "├─AvgPool2d: 1-6                         [32768, 64, 5, 5]         --\n",
       "├─Flatten: 1-7                           [32768, 1600]             --\n",
       "├─Linear: 1-8                            [32768, 120]              192,120\n",
       "├─ReLU: 1-9                              [32768, 120]              --\n",
       "├─Linear: 1-10                           [32768, 84]               10,164\n",
       "├─ReLU: 1-11                             [32768, 84]               --\n",
       "├─Linear: 1-12                           [32768, 10]               850\n",
       "==========================================================================================\n",
       "Total params: 242,222\n",
       "Trainable params: 242,222\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 148.73\n",
       "==========================================================================================\n",
       "Input size (MB): 102.76\n",
       "Forward/backward pass size (MB): 6666.32\n",
       "Params size (MB): 0.97\n",
       "Estimated Total Size (MB): 6770.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v2 = CNN_v2()\n",
    "summary(cnn_v2, input_size=(32768, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_v3                                   [1024, 10]                --\n",
       "├─Conv2d: 1-1                            [1024, 24, 28, 28]        624\n",
       "├─ReLU: 1-2                              [1024, 24, 28, 28]        --\n",
       "├─AvgPool2d: 1-3                         [1024, 24, 14, 14]        --\n",
       "├─Conv2d: 1-4                            [1024, 64, 10, 10]        38,464\n",
       "├─ReLU: 1-5                              [1024, 64, 10, 10]        --\n",
       "├─AvgPool2d: 1-6                         [1024, 64, 5, 5]          --\n",
       "├─Flatten: 1-7                           [1024, 1600]              --\n",
       "├─Linear: 1-8                            [1024, 120]               192,120\n",
       "├─ReLU: 1-9                              [1024, 120]               --\n",
       "├─Linear: 1-10                           [1024, 10]                1,210\n",
       "==========================================================================================\n",
       "Total params: 232,418\n",
       "Trainable params: 232,418\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.64\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 207.63\n",
       "Params size (MB): 0.93\n",
       "Estimated Total Size (MB): 211.78\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v3 = CNN_v3()\n",
    "summary(cnn_v3, input_size=(1024, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p50aWdYI5YqG"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OO04799z5YqH"
   },
   "source": [
    "Let's define the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xeBFcssY5YqH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss includes softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "500YiRwa5YqI"
   },
   "source": [
    "Also, define a device where to store the data and the model (cpu or gpu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3HQo_6Kb5YqJ"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK9sl8w_5YqK"
   },
   "source": [
    "During training, we will control the quality on the training and validation set. This produces duplicates of the code. That's why we will define a function evaluate_loss_acc to evaluate our model on different data sets. In the same manner, we define function train_epoch to perform one training epoch on traiing data. Please note that we will compute the training loss _after_ each epoch (not averaging it during epoch).\n",
    "\n",
    "In the propotypes, train and eval modes are noted. In our case, we don't need them (because we don't use neither dropout nor batch normalization). However, we will switch the regime so you can use this code in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-9aShtYQWkt"
   },
   "source": [
    "### <font color='red'>[TODO] Реализуйте функции обучение модели </font>\n",
    "\n",
    "В части вам нужно написать циклы обучения моделей, вы можете ориентировать на ноутбук семинара при их выполнении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "59ACywmqwWpS"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "class Trainer:\n",
    "    def set_wandb(self):\n",
    "        self.config = {\n",
    "                'architecture'    : 'Lenet-5_v3',\n",
    "                'optimizer'       : 'AdamW',\n",
    "                'learning_rate'   : 3e-3,\n",
    "                'weight_decay'    : 1e-6,\n",
    "                'optimizer_kwargs': {'betas': (0.9, 0.999), 'eps': 1e-7},\n",
    "                'scheduler_name'  : 'StepLr',\n",
    "                'scheduler_kwargs': {'eta_min': 2e-4, 'T_max': 300, 'gamma': 0.85,'step_size': 7, },\n",
    "                'epochs'          : 300,\n",
    "                'batch_size'      : 2048\n",
    "            }\n",
    "        wandb.login(key='84d6a92704bf4bf19d2ecc87a55eea5ce77a8725')\n",
    "        self.run = wandb.init(project='dl_homework', config=self.config)\n",
    "        self.model_name = 'run_' + self.run.name + '_model'\n",
    "        self.start_epoch = 0\n",
    "        self.num_epochs  = self.config['epochs']\n",
    "\n",
    "    def __init__(self):\n",
    "        self.set_wandb()\n",
    "        self.set_data()\n",
    "        self.set_net()\n",
    "        self.set_opt_sched()\n",
    "        self.entropy = nn.CrossEntropyLoss()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.best_acc = 0\n",
    "\n",
    "    def criterion(self, outputs, targets, config):\n",
    "        loss_entropy = self.entropy(outputs, targets)\n",
    "        config['entropy_loss'].append(loss_entropy.item())\n",
    "        config['loss'].append(loss_entropy.item())\n",
    "        return loss_entropy\n",
    "\n",
    "    def metrics(self, outputs, targets, config):\n",
    "        predict = self.softmax(outputs)\n",
    "        predict = torch.argmax(outputs, dim=1)\n",
    "        config['Accuracy'].append(predict.eq(targets).sum().item()/targets.size(0))\n",
    "\n",
    "    def validate(self, i_epoch):\n",
    "        # Test\n",
    "        self.net.eval()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        config = self.get_config()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loop = tqdm(enumerate(self.test_loader), total=len(self.test_loader), leave=False)\n",
    "            for batch_idx, (inputs, targets) in loop:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.criterion(outputs, targets, config)\n",
    "                # Calculate and summary metrics\n",
    "                self.metrics(outputs, targets, config)\n",
    "                # LOOPA and PUPA\n",
    "                loop.set_description(f\"Epoch (Test)[{i_epoch}/{self.num_epochs}]\")\n",
    "                loop.set_postfix(Accuracy=np.mean(config['Accuracy']), loss=np.mean(config['loss']))\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            config['i_epoch'] = i_epoch\n",
    "            self.wandb_log(config, name='Test')\n",
    "\n",
    "        # Save checkpoint.\n",
    "        acc = 100.*np.mean(config['Accuracy'])\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.save(i_epoch, self.model_name + f'_best')\n",
    "\n",
    "    def train(self, i_epoch):\n",
    "        # Train\n",
    "        config = self.get_config()\n",
    "        self.net.train()\n",
    "        loop = tqdm(enumerate(self.train_loader), total=len(self.train_loader), leave=False)\n",
    "        for batch_idx, (inputs, targets) in loop:\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            outputs = self.net(inputs)\n",
    "            loss = self.criterion(outputs, targets, config)\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # Make backward step\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            # Calculate and summary metrics\n",
    "            self.metrics(outputs, targets, config)\n",
    "            # LOOPA and PUPA\n",
    "            loop.set_description(f\"Epoch (Train)[{i_epoch}/{self.num_epochs}]\")\n",
    "            loop.set_postfix(Accuracy=np.mean(config['Accuracy']), loss=np.mean(config['loss']))\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        config['i_epoch'] = i_epoch\n",
    "        self.wandb_log(config, name='Train')\n",
    "\n",
    "    def fit(self):\n",
    "        for i_epoch in range(self.num_epochs):\n",
    "            self.train(i_epoch)\n",
    "            self.validate(i_epoch)\n",
    "            self.scheduler.step()\n",
    "        self.run.finish()\n",
    "\n",
    "    def set_opt_sched(self):\n",
    "        self.optimizer = optim.AdamW(\n",
    "            params       = self.net.parameters(),\n",
    "            lr           = self.config['learning_rate'],\n",
    "            betas        = self.config['optimizer_kwargs']['betas'],\n",
    "            eps          = self.config['optimizer_kwargs']['eps'],\n",
    "            weight_decay = self.config['weight_decay']\n",
    "            )\n",
    "       \n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            self.optimizer,\n",
    "            step_size = self.config['scheduler_kwargs']['step_size'],\n",
    "            gamma     = self.config['scheduler_kwargs']['gamma']\n",
    "            )\n",
    "\n",
    "    def wandb_log(self, config, name):\n",
    "        wandb.log({f'{name} entropy_loss': np.mean(config['entropy_loss']),\n",
    "                   f'{name} Accuracy'    : np.mean(config['Accuracy']),\n",
    "                   'Epoch'               : config['i_epoch']})\n",
    "\n",
    "    def load(self, filename):\n",
    "        checkpoint = torch.load(f'./checkpoint/{filename}.pth')\n",
    "        self.set_net()\n",
    "        self.net.load_state_dict(checkpoint['net'])\n",
    "        self.set_opt_sched()\n",
    "        self.net         = self.net.to(self.device)\n",
    "        self.best_acc    = checkpoint['acc']\n",
    "        self.start_epoch = checkpoint['epoch']\n",
    "        wandb.watch(self.net, log_freq=100)\n",
    "\n",
    "    def save(self, i_epoch, name):\n",
    "        state = {\n",
    "            'net'      : self.net.state_dict(),\n",
    "            'acc'      : self.best_acc,\n",
    "            'epoch'    : i_epoch,\n",
    "            }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, f'./checkpoint/{name}.pth')\n",
    "        print(f'Saved... Epoch[{i_epoch}]')\n",
    "\n",
    "    def set_net(self):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.set_device(1)\n",
    "        #self.net = CNN()\n",
    "        #self.net = CNN_v2()\n",
    "        self.net = CNN_v3()\n",
    "\n",
    "        self.net = self.net.to(self.device)\n",
    "        wandb.watch(self.net, log_freq=100)\n",
    "\n",
    "    \n",
    "    def set_data(self):\n",
    "        X_train, y_train, X_test, y_test = load_mnist()\n",
    "        X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()\n",
    "        X_test, y_test   = torch.from_numpy(X_test).float(),torch.from_numpy(y_test).long()\n",
    "\n",
    "        dataset_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset_train, \n",
    "                                             batch_size=self.config['batch_size'], \n",
    "                                             num_workers=10,\n",
    "                                             pin_memory=True,\n",
    "                                             shuffle=True,\n",
    "                                             drop_last=False)\n",
    "\n",
    "        dataset_test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset_test, \n",
    "                                             batch_size=self.config['batch_size'], \n",
    "                                             num_workers=10,\n",
    "                                             pin_memory=True,\n",
    "                                             shuffle=False,\n",
    "                                             drop_last=False)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'loss'        : [],\n",
    "            'entropy_loss': [],\n",
    "            'i_epoch'     : 0,\n",
    "            'Accuracy'    : [],\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIl21h4g5YqM"
   },
   "source": [
    "### <font color='red'>[TODO] Обучение модели </font>\n",
    "\n",
    "Train the neural network, using defined functions. Use Adam as an optimizer, learning_rate=0.001, number of epochs = 20. For hold out, use val_loader, not test_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "g9Z-1m-45YqN",
    "outputId": "c9993c98-652c-45dd-a915-00ddd6fa4b4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:94cstbrl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fceb35ec7ee4bde957255bc6dc72095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Test Accuracy</td><td>▁▁▁▁▂▂▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Test entropy_loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>Train entropy_loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>56</td></tr><tr><td>Test Accuracy</td><td>0.3241</td></tr><tr><td>Test entropy_loss</td><td>2.27962</td></tr><tr><td>Train Accuracy</td><td>0.32027</td></tr><tr><td>Train entropy_loss</td><td>2.27974</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-dew-23</strong> at: <a href='https://wandb.ai/kreininmv/dl_homework/runs/94cstbrl' target=\"_blank\">https://wandb.ai/kreininmv/dl_homework/runs/94cstbrl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230925_223552-94cstbrl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:94cstbrl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kreinin.mv/university/deep_learning/hw2/wandb/run-20230925_224043-wxavkep6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kreininmv/dl_homework/runs/wxavkep6' target=\"_blank\">iconic-hill-24</a></strong> to <a href='https://wandb.ai/kreininmv/dl_homework' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kreininmv/dl_homework' target=\"_blank\">https://wandb.ai/kreininmv/dl_homework</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kreininmv/dl_homework/runs/wxavkep6' target=\"_blank\">https://wandb.ai/kreininmv/dl_homework/runs/wxavkep6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved... Epoch[37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Trainer()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model.load('run_fresh-sunset-13_model_best')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 102\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(i_epoch)\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[58], line 62\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, i_epoch)\u001b[0m\n\u001b[1;32m     60\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch (Test)[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_postfix(Accuracy\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]), loss\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     65\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m i_epoch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Trainer()\n",
    "#model.load('run_fresh-sunset-13_model_best')\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjpBaZ7fSiP7"
   },
   "source": [
    "### <font color='red'>[TODO] Проведите эксперименты с моделью </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE5cJCEc5Yqq"
   },
   "source": [
    "\n",
    "### Choosing  learning_rate and batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_plUpWK5Yqq"
   },
   "source": [
    "Plot accuracy on the training and testing set v. s. training epoch for different learning parameters: learning rate$ \\in \\{0.0001, 0.001, 0.01\\}$, batch size $\\in \\{64, 256\\}$.\n",
    "\n",
    "The best option is to plot training curves on the left graph and validation curves on the right graph with the shared y axis (use plt.ylim).\n",
    "\n",
    "How do learning rate and batch size affect the final quality of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lc5mgJmZ5Yqr"
   },
   "source": [
    "### Ответ:\n",
    "Я не знаю, как правильно прикрепить графики экспериментов из wandb в тетрадку, но могу скинуть скришноты оттуда или как-то дать доступ к проекту.\n",
    "Батч сайз стоит брать побольше, т.к. с увеличентем батча уменьшается стохастичность градиента исходной, что положительно сказывается на скорости сходимости, но тут тоже нужно следить, т.к. при размере батча в 256 сходимость была быстрее за эпоху, чем при батче в 256, но это компенсируется сравнительной скоростью, с которой проходит обучение одной эпохи, при батче 1024.\n",
    "\n",
    "В качестве оптимизатора был выбран AdamW (он самый хайповый), т.к. многие эксперты отмечают его при оптимизации нейронных сетей, что сходится с моим интересом к нему, в качестве beta для него были выбраны стандартные $=(0.9, 0.999)$, weight_decay $= 1e-6$, learning rate $= 3e-3$, что в 10 раз больше рекомендации Андрея Карпатова, в качестве шедулера выбран StepLr с параметрами: step_size $=7$ и gamma $=0.85$.\n",
    "\n",
    "Также в качестве изменения был убран последний слой в сетке c softmax, чтобы была вариативность использования после (но здесь я никак ей не пользовался).\n",
    "\n",
    "Также был выбран batch_size $= 32768$, чтобы позволило убрать всю стохастичность в задаче и теперь бы берем полный градиент по всей выборке, скорость работы увеличилась в разы, т.к. pin_memory в loader позволяет не тратить время на загрузку, надо выбрать learning rate побольше при таком размере, но зато эпохи происходят мгновенно, но тут нужно брать lerning rate поменьше и тренировать без шедулера, тогда сетка показывает наилучший результат, что в целом сходится с теорией из оптимизаци. Также была применена техника рестартов сетки с претрейна...\n",
    "\n",
    "Был попробован SGD с batch_size $=32768$, но он не дает результата ни при достаточно большом learning_rate $=2e-2$, так и при маленьком $=1e-5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEG3Nu9w5Yqs"
   },
   "source": [
    "### Changing the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqMV5M1j5Yqs"
   },
   "source": [
    "Try to modify our architecture: increase the number of filters and to reduce the number of fully-connected layers.\n",
    "\n",
    "Insert numbers in the brackets:\n",
    "* LeNet-5 classic (6 and 16 convolutions):  training acc: (0.9986)  validation acc: (0.9913)\n",
    "* Number of convolutions x 4 (24 и 64 convolutions):  training acc: (0.9978)  validation acc: (0.9928)\n",
    "* Removing fully connected layer: the previous network with 1 FC layer: training acc: (0.9973)  validation acc: (0.9929)\n",
    "\n",
    "P.s. есть ещё training acc: (0.9999), validation acc: (0.9913)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoX-g-5n5Yqu"
   },
   "source": [
    "Choose the learning rate, batch size and the architecture based on your experiments. Train a network on the full dataset and print accuracy on the full test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на графики и описания экспериментов:\n",
    "https://api.wandb.ai/links/kreininmv/vz4rl7eu"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
